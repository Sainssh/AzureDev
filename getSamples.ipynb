{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_17704\\3164684681.py:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection samples is completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def genrate_dataset():\n",
    "    face_classifier=cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\");\n",
    "    def face_cropper(img):\n",
    "        gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faces=face_classifier.detectMultiScale(gray,1.3,5)\n",
    "\n",
    "        if faces is ():\n",
    "            return None\n",
    "        for (x,y,w,h) in faces:\n",
    "            cropped_Face=img[y:y+h,x:x+w]\n",
    "        return cropped_Face\n",
    "    cap=cv2.VideoCapture(0)\n",
    "    img_id=1\n",
    "\n",
    "    while True:\n",
    "        ret,Fram=cap.read()\n",
    "        if face_cropper(Fram) is not    None:\n",
    "            img_id+=1\n",
    "            face=cv2.resize(face_cropper(Fram),(200,200))\n",
    "            face=cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "            file_name_path=\"data/\"+\"second.\"+str(img_id)+\".jpg\"\n",
    "            #file_name_path=\"Visulaization/\"+str(img_id)+'.jpg'\n",
    "            cv2.imwrite(file_name_path,face)\n",
    "            cv2.putText(face,str(img_id),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "\n",
    "            cv2.imshow(\"CroppedFace\",face)\n",
    "            if cv2.waitKey(1)==13 or int(img_id)==1000:\n",
    "                break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Collection samples is completed\")\n",
    "\n",
    "genrate_dataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_17704\\88685276.py:7: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection samples is completed\n"
     ]
    }
   ],
   "source": [
    "def capturePhoto():\n",
    "    face_classifier=cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\");\n",
    "    def face_cropper(img):\n",
    "        gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faces=face_classifier.detectMultiScale(gray,1.3,5)\n",
    "\n",
    "        if faces is ():\n",
    "            return None\n",
    "        for (x,y,w,h) in faces:\n",
    "            cropped_Face=img[y:y+h,x:x+w]\n",
    "        return cropped_Face\n",
    "    cap=cv2.VideoCapture(0)\n",
    "    img_id=1\n",
    "\n",
    "    while True:\n",
    "        ret,Fram=cap.read()\n",
    "        if face_cropper(Fram) is not None:\n",
    "            img_id+=1\n",
    "            face=cv2.resize(face_cropper(Fram),(200,200))\n",
    "            face=cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "            #file_name_path=\"data/\"+\"first.\"+str(img_id)+\".jpg\"\n",
    "            file_name_path=\"Visulaization/\"+str(img_id)+'.jpg'\n",
    "            cv2.imwrite(file_name_path,face)\n",
    "            cv2.putText(face,str(img_id),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "\n",
    "            cv2.imshow(\"CroppedFace\",face)\n",
    "            if cv2.waitKey(1)==13 or int(img_id)==2:\n",
    "                break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Collection samples is completed\")\n",
    "capturePhoto()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CREATE LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def my_label(image_name):\n",
    "    name=image_name.split('.')[-3]\n",
    "\n",
    "    if name==\"first\":\n",
    "        return np.array([1,0,0])\n",
    "    elif name==\"second\":\n",
    "        return np.array([0,1,0])\n",
    "    elif name==\"third\":\n",
    "        return np.array([0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from random import shuffle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_data():\n",
    "    data=[]\n",
    "\n",
    "    for img in tqdm(os.listdir(\"data\")):\n",
    "        path=os.path.join(\"data\",img)\n",
    "        img_data=cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img_data=cv2.resize(img_data,(50,50))\n",
    "        data.append([np.array(img_data),my_label(img)])\n",
    "    shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1998/1998 [00:00<00:00, 2338.34it/s]\n"
     ]
    }
   ],
   "source": [
    "data=my_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 50, 50, 1)\n",
      "(1298, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "train=data[:700]\n",
    "test=data[700:]\n",
    "X_train=np.array([i[0] for i in train]).reshape(-1,50,50,1)\n",
    "print(X_train.shape)\n",
    "\n",
    "Y_train=[i[1] for i in train]\n",
    "X_test=np.array([i[0] for i in test]).reshape(-1,50,50,1)\n",
    "\n",
    "print(X_test.shape)\n",
    "Y_test=[i[1] for i in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn \n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data,dropout,fully_connected\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 131  | total loss: \u001b[1m\u001b[32m0.29161\u001b[0m\u001b[0m | time: 0.928s\n",
      "| Adam | epoch: 012 | loss: 0.29161 - acc: 0.9713 -- iter: 640/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-196 (fill_feed_dict_queue):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tflearn\\data_flow.py\", line 187, in fill_feed_dict_queue\n",
      "    data = self.retrieve_data(batch_ids)\n",
      "  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tflearn\\data_flow.py\", line 222, in retrieve_data\n",
      "    utils.slice_array(self.feed_dict[key], batch_ids)\n",
      "  File \"c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tflearn\\utils.py\", line 204, in slice_array\n",
      "    return X[start]\n",
      "IndexError: index 700 is out of bounds for axis 0 with size 700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 132  | total loss: \u001b[1m\u001b[32m0.26337\u001b[0m\u001b[0m | time: 2.017s\n",
      "| Adam | epoch: 012 | loss: 0.26337 - acc: 0.9742 | val_loss: 1.14137 - val_acc: 0.2558 -- iter: 700/700\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "convnet = input_data(shape=[50,50,1])\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "# 32 filters and stride=5 so that the filter will move 5 pixel or unit at a time\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "convnet = fully_connected(convnet, 3, activation='softmax') #2 for two dataset\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate = 0.001, loss='categorical_crossentropy')\n",
    "model = tflearn.DNN(convnet, tensorboard_verbose=1)\n",
    "model.fit(X_train, Y_train, n_epoch=12, validation_set=(X_test, Y_test), show_metric = True, run_id=\"FRS\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_visulization():\n",
    "    Vdata=[]\n",
    "    for img in tqdm(os.listdir(\"Visulaization\")):\n",
    "        path=os.path.join(\"Visulaization\",img)\n",
    "        img_num=img.split('.')[0]\n",
    "        img_data=cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img_data=cv2.resize(img_data,(50,50))\n",
    "        Vdata.append([np.array(img_data),img_num])\n",
    "    shuffle(Vdata)\n",
    "    return Vdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n"
     ]
    }
   ],
   "source": [
    "Vdata=data_for_visulization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt   # pip install matplotlib\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "for num, data in enumerate(Vdata[:20]):\n",
    "    img_data = data[0]\n",
    "    y = fig.add_subplot(5,5, num+1)\n",
    "    image = img_data\n",
    "    data = img_data.reshape(50,50,1)\n",
    "    model_out = model.predict([data])[0]\n",
    "    label=False\n",
    "    if np.argmax(model_out) == 0:\n",
    "        my_label = 'first'\n",
    "        label=True\n",
    "    elif np.argmax(model_out) == 1:\n",
    "        my_label = 'second'\n",
    "        label=False\n",
    "    elif np.argmax(model_out) == 2:\n",
    "        my_label = 'None'\n",
    "        label=False\n",
    "    else:\n",
    "        my_label='none'\n",
    "        label=False\n",
    "        \n",
    "    y.imshow(image, cmap='gray')\n",
    "    plt.title(my_label)\n",
    "    \n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tkinter as tk\n",
    "from tkinter import ttk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=tk.Tk()\n",
    "root.geometry('400x250')\n",
    "userString=tk.StringVar(root)\n",
    "passString=tk.StringVar(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Login():\n",
    "    label_1=tk.Label(root,text=\"Username\").place(x = 60, y =50)\n",
    "    inpUser=tk.Entry(root,width=30,textvariable=userString).place(x = 130, y = 50)\n",
    "\n",
    "    label_2=tk.Label(root,text=\"Password\").place(x = 60, y = 90)\n",
    "    inpPass=tk.Entry(root,width=30,textvariable=passString,show=\"*\").place(x = 130, y = 90)\n",
    "\n",
    "    Button=tk.Button(root,text=\"Submit\",command=getValues).place(x = 170, y = 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValues():\n",
    "    userVal=userString.get()\n",
    "    passVal=passString.get()\n",
    "\n",
    "    if(userVal.rstrip()=='hello' and passVal.rstrip()=='world'):\n",
    "        print(\"Login Sucess\")\n",
    "\n",
    "        for i in root.winfo_children():\n",
    "            i.destroy()\n",
    "    \n",
    "        main_menu()\n",
    "        \n",
    "    else:\n",
    "        print(\"Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked = tk.StringVar()\n",
    "button_var = tk.StringVar()\n",
    "button_var.set(\"Disable\")\n",
    "def disable_func():\n",
    "    if (str(button_var.get()) == 'Disable'):\n",
    "        button_var.set(\"Enable\")\n",
    "    elif (str(button_var.get()) == 'Enable'):\n",
    "        button_var.set(\"Disable\")\n",
    "\n",
    "def genrate_dataset():\n",
    "    pass\n",
    "\n",
    "def getvall():\n",
    "    print(str(clicked.get()).split(' ')[0])\n",
    "\n",
    "def main_menu():    \n",
    "    # clicked.set('5 mins')\n",
    "    \n",
    "    label_1=tk.Label(root,text=\"Interval\", anchor=tk.W).place(x = 20, y =20)\n",
    "    options = ttk.Combobox(root, textvariable = clicked)\n",
    "    options['values'] = tuple(f'{i} mins' for i in range(5, 30 + 1, 5))\n",
    "    options['state'] = 'readonly'\n",
    "    options.place(x = 80, y = 19)\n",
    "\n",
    "    button=tk.Button(root,text=\"Select\",command=getvall, width=10).place(x = 80, y = 45)\n",
    "\n",
    "\n",
    "    label_2=tk.Label(root,text=\"Add user\", anchor=tk.W).place(x = 20, y = 90)\n",
    "    button=tk.Button(root,text=\"Add\",command=genrate_dataset, width=10).place(x = 80, y = 90)\n",
    "\n",
    "    disable=tk.Label(root,text=\"Disable IR\", anchor=tk.W).place(x = 20, y = 130)\n",
    "    disable_button=tk.Button(root,command=disable_func, textvariable=button_var, width=10).place(x = 80, y = 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "Login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Sucess\n"
     ]
    }
   ],
   "source": [
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "229cdfb8eedfa4964725b7eb0da8d7a63b25d97a6ab808f09bd6b506844c0629"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
